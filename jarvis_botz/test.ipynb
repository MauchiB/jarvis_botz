{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e887e502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\odino\\Desktop\\botz\\jarvis_botz\\botz_venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "import os\n",
    "import sys\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "sys.path.append(os.path.abspath(\"C:/Users/odino/Desktop/botz\"))\n",
    "from config import aiconfig\n",
    "from ai.graph import graph\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from langchain.agents import initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6f92aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odino\\AppData\\Local\\Temp\\ipykernel_3612\\3353824168.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fda41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = graph.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20eded74",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'input': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhi\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\odino\\Desktop\\botz\\jarvis_botz\\botz_venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5356\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5348\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5349\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5350\u001b[39m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[32m   5351\u001b[39m     config: Optional[RunnableConfig] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   5352\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5353\u001b[39m ) -> Output:\n\u001b[32m   5354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.invoke(\n\u001b[32m   5355\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m5356\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   5357\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5358\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\odino\\Desktop\\botz\\jarvis_botz\\botz_venv\\Lib\\site-packages\\langchain_core\\runnables\\history.py:603\u001b[39m, in \u001b[36mRunnableWithMessageHistory._merge_configs\u001b[39m\u001b[34m(self, *configs)\u001b[39m\n\u001b[32m    596\u001b[39m     example_config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: example_configurable}\n\u001b[32m    597\u001b[39m     msg = (\n\u001b[32m    598\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing keys \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(missing_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in config[\u001b[39m\u001b[33m'\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m'\u001b[39m\u001b[33m] \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected keys are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(expected_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhen using via .invoke() or .stream(), pass in a config; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    601\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33me.g., chain.invoke(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    602\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expected_keys) == \u001b[32m1\u001b[39m:\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parameter_names:\n\u001b[32m    607\u001b[39m         \u001b[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Missing keys ['session_id'] in config['configurable'] Expected keys are ['session_id'].When using via .invoke() or .stream(), pass in a config; e.g., chain.invoke({'input': 'foo'}, {'configurable': {'session_id': '[your-value-here]'}})"
     ]
    }
   ],
   "source": [
    "model.invoke('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e816d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Hello there!' additional_kwargs={} response_metadata={} id='run-fd9d00fe-60c7-4891-85a2-88799a75ba4b'\n",
      "content=\" It's great to see you again.\" additional_kwargs={} response_metadata={} id='run-fd9d00fe-60c7-4891-85a2-88799a75ba4b'\n",
      "content=' What would you like to talk about or need help with this time?' additional_kwargs={} response_metadata={} id='run-fd9d00fe-60c7-4891-85a2-88799a75ba4b'\n",
      "content=' ðŸŒŸâœ¨' additional_kwargs={} response_metadata={} id='run-fd9d00fe-60c7-4891-85a2-88799a75ba4b'\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'stop'} id='run-fd9d00fe-60c7-4891-85a2-88799a75ba4b'\n"
     ]
    }
   ],
   "source": [
    "async for out in model.astream({'input':'hi', 'style':'lol'}, config={'configurable':{'session_id':'12212'}}):\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e635fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "data = {}\n",
    "def get_session_id(id: str) -> str:\n",
    "    if id not in data:\n",
    "        data[id] = ChatMessageHistory()\n",
    "    return data[id]\n",
    "\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', \"act yourself as a {style}\"),\n",
    "        ('placeholder', '{history}'),\n",
    "        ('human', '{input}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "running = template | model\n",
    "\n",
    "run = RunnableWithMessageHistory(running, get_session_history=get_session_id, input_messages_key='input', output_messages_key='output',\n",
    "                                 history_messages_key='history')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca5e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01194361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Listen up, pal! What do you want? I'm busy here. Make it quick and to the point if you're gonna bother me with small talk.\", additional_kwargs={}, response_metadata={'token_usage': Usage(prompt_tokens=36, completion_tokens=31, total_tokens=67, precached_prompt_tokens=1), 'model_name': 'GigaChat-2-Max:2.0.28.2', 'finish_reason': 'stop'}, id='run-781e3a6c-6ed0-4d14-a05b-421e5695a9fd-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.invoke({'input':'hi there', 'style':'aggresive'}, config={'configurable':{'session_id': 'user1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87d91de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked \"hi there\". Now what is it that you really need? Stop wasting my time with pleasantries.', additional_kwargs={}, response_metadata={'token_usage': Usage(prompt_tokens=193, completion_tokens=25, total_tokens=218, precached_prompt_tokens=1), 'model_name': 'GigaChat-2-Max:2.0.28.2', 'finish_reason': 'stop'}, id='run-6739815a-28d0-4643-affb-10123358c4e4-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.invoke({'input':'my previous message to you was?', 'style':'aggresive'}, config={'configurable':{'session_id': 'user1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f58ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, Integer, String, Float\n",
    "from sqlalchemy.orm import declarative_base, sessionmaker\n",
    "\n",
    "\n",
    "engine = create_engine('sqlite:///base.db', echo=False)\n",
    "\n",
    "\n",
    "\n",
    "SessionLocal = sessionmaker(bind=engine, autoflush=True)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    username = Column(String)\n",
    "    tokens = Column(Float, default=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Base.metadata.create_all(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user(id):\n",
    "    with SessionLocal() as session:\n",
    "        return session.get(User, id)\n",
    "    \n",
    "\n",
    "def add_user(id, username):\n",
    "    with SessionLocal() as session:\n",
    "        if session.query(User).filter_by(id=id).first():\n",
    "            return False\n",
    "        user = User(id=id, username=username)\n",
    "        session.add(user)\n",
    "        session.commit()\n",
    "        return user\n",
    "    \n",
    "\n",
    "def add_token(id, num):\n",
    "    with SessionLocal() as session:\n",
    "        user = session.get(User, id)\n",
    "        if not user:\n",
    "            return False\n",
    "        \n",
    "        user.tokens += num\n",
    "        print(user.tokens)\n",
    "        session.commit()\n",
    "        return True\n",
    "\n",
    "def remove_token(id, num):\n",
    "    with SessionLocal() as session:\n",
    "        user = session.get(User, id)\n",
    "        if not user:\n",
    "            return False\n",
    "        \n",
    "        user.tokens -= num\n",
    "        session.commit()\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf128ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0\n",
      "12.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "user = add_user(1, 'lol')\n",
    "\n",
    "user = get_user(1)\n",
    "\n",
    "token = add_token(1, 2)\n",
    "\n",
    "\n",
    "token = remove_token(1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526844e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "with SessionLocal() as s:\n",
    "    print(s.query(User).filter_by(id=1).first().tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botz_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
